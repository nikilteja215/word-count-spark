
# ğŸ“˜ Report: Hands-on #11 â€“ AWS EC2, Spark & Docker Web App
**Submitted by:** Nikil Teja  
**Student Email:** sswarna@uncc.edu

---

## âœ… Objective

This assignment focused on:
- Running a PySpark word count on AWS EC2 with S3 integration.
- Creating and deploying a Dockerized Node.js web application.
- Learning cloud-based big data processing and container deployment.

---

## ğŸ”¹ TASK 1: Spark Word Count on EC2 + S3

### âš™ï¸ EC2 Setup (Amazon Linux 2)

```bash
ssh -i "word_key_pair.pem" ec2-user@<EC2_PUBLIC_IP>
```
ğŸ”¹ *Connects to the EC2 instance using SSH and your private key.*

```bash
sudo yum update -y
```
ğŸ”¹ *Updates all system packages to the latest versions.*

```bash
sudo yum install java-11 -y
```
ğŸ”¹ *Installs Java 11 â€” required for Spark to run.*

```bash
export JAVA_HOME=$(dirname $(dirname $(readlink -f $(which java))))
```
ğŸ”¹ *Sets the JAVA_HOME environment variable properly.*

```bash
java --version
```
ğŸ”¹ *Verifies that Java is installed and accessible.*

```bash
sudo mount -o remount,size=2G /tmp
```
ğŸ”¹ *Increases `/tmp` directory size to avoid Spark temporary storage issues.*

```bash
sudo yum install python3-pip -y
pip3 install pyspark
```
ğŸ”¹ *Installs pip and then installs PySpark (the Python interface for Apache Spark).*

---

### âš™ï¸ PySpark Word Count Script

**File: `word_count.py`**

```python
from pyspark.sql import SparkSession

# AWS Credentials
AWS_ACCESS_KEY_ID = 'YOUR_ACCESS_KEY' 
AWS_SECRET_ACCESS_KEY = 'YOUR_SECRET_KEY' 

# S3 paths
S3_INPUT = 's3a://nikilteja/word_count_nikil.txt'
S3_OUTPUT = 's3a://nikilteja/output_folder/'

# Spark Session
spark = SparkSession.builder \
    .appName("WordCount") \
    .config("spark.jars.packages", "org.apache.hadoop:hadoop-aws:3.3.1,com.amazonaws:aws-java-sdk-bundle:1.11.901") \
    .getOrCreate()

# Hadoop S3 Configuration
hadoop_conf = spark.sparkContext._jsc.hadoopConfiguration()
hadoop_conf.set("fs.s3a.access.key", AWS_ACCESS_KEY_ID)
hadoop_conf.set("fs.s3a.secret.key", AWS_SECRET_ACCESS_KEY)

# Word Count Logic
text_file = spark.sparkContext.textFile(S3_INPUT)
counts = text_file.flatMap(lambda line: line.split()) \
                  .map(lambda word: (word, 1)) \
                  .reduceByKey(lambda a, b: a + b)
counts.saveAsTextFile(S3_OUTPUT)
spark.stop()
```

ğŸ”¹ *This script reads a text file from S3, performs word count using PySpark, and writes the output back to S3.*

---

## ğŸ”¹ TASK 2: Dockerized Node.js Web App

### ğŸ“ Create Node.js App

```bash
mkdir node-webserver && cd node-webserver
```
ğŸ”¹ *Creates and enters the project folder.*

```bash
npm init -y
```
ğŸ”¹ *Initializes a Node.js project with default settings.*

```bash
npm install express
```
ğŸ”¹ *Installs the Express web framework.*

---

**File: `server.js`**

```js
const express = require('express');
const app = express();
const port = 3000;

app.get('/', (req, res) => {
    res.send('Hello, World! Running in Docker.');
});

app.listen(port, () => console.log(`Server running at http://localhost:${port}`));
```

ğŸ”¹ *Sets up a basic Express server that responds to HTTP GET requests.*

---

### ğŸ³ Dockerfile

```Dockerfile
FROM node:20               # changed from node:14 â†’ node:20
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
EXPOSE 3000
CMD ["node", "server.js"]
```

ğŸ”¹ *Defines the Docker image:*
- Uses Node.js 20 instead of 14
- Installs dependencies
- Starts the server

---

### ğŸ”§ Docker on EC2

```bash
sudo yum install docker -y
```
ğŸ”¹ *Installs Docker.*

```bash
sudo service docker start
```
ğŸ”¹ *Starts Docker service.*

```bash
sudo usermod -aG docker ec2-user
```
ğŸ”¹ *Adds the current user to the Docker group.*

```bash
logout  # then re-login for group changes to apply
```

---

### ğŸ› ï¸ Build & Run Container

```bash
docker build -t nikilteja215/webserver:latest .
```
ğŸ”¹ *Builds the Docker image.*

```bash
docker run -d -p 80:3000 nikilteja215/webserver:latest
```
ğŸ”¹ *Runs the container and maps port 80 of EC2 to 3000 inside the container.*

---

### ğŸŒ Access App

```bash
curl http://localhost
```
ğŸ”¹ *Checks if the app is running locally.*

```bash
curl http://checkip.amazonaws.com
```
ğŸ”¹ *Gets your EC2â€™s public IP to test in browser.*

Access in browser:  
**http://<EC2_PUBLIC_IP>**  
âœ”ï¸ *App says: "Hello, World! Running in Docker."*

---

### ğŸ“¤ DockerHub Push

```bash
docker login
```
ğŸ”¹ *Logs into DockerHub.*

```bash
docker tag nikilteja215/webserver:latest nikilteja215/webserver:latest
docker push nikilteja215/webserver:latest
```

## ğŸ”§ Troubleshooting Done

- âŒ `Output directory already exists` â†’ deleted S3 output folder
- ğŸ›‘ GitHub blocking push due to secrets â†’ removed AWS keys and used `git filter-repo`
- âš ï¸ Merge error (`unrelated histories`) â†’ fixed with `--allow-unrelated-histories`
- âœ‰ï¸ Email privacy error â†’ used GitHub noreply email

---

## ğŸ”— Links

- **GitHub Repo:** [https://github.com/nikilteja215/word-count-spark/tree/main](https://github.com/nikilteja215/word-count-spark/tree/main)
- **DockerHub Repo:** [https://hub.docker.com/repository/docker/nikilteja215/webserver/general](https://hub.docker.com/repository/docker/nikilteja215/webserver/general)
- **Web App (EC2):** http://3.237.83.253

---

## âœ… Submission Checklist

- [x] EC2 instance created
- [x] PySpark word count completed
- [x] Docker container built and deployed
- [x] DockerHub image pushed
- [x] GitHub repo cleaned and submitted
- [x] Final report written

---

## ğŸ™Œ Done By

**Nikil Teja**  
UNCC Student  
Email: sswarna@uncc.edu  
GitHub: [@nikilteja215](https://github.com/nikilteja215)
